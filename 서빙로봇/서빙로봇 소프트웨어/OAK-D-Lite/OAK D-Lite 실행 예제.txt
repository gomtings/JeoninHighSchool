# OAK D-Lite 파이썬 객체 감지 예제 실행 가이드 (Windows 환경 기준)

## 목차
1.  OAK D-Lite란?
2.  실행 환경 준비
3.  DepthAI 저장소 클론 및 데모 실행
4.  객체 감지 예제 코드 실행
5.  문제 발생 시 대처 방안 (Troubleshooting)

---

## 1. OAK D-Lite란?

*   **O**penCV **A**I **K**it - **D**epth - **Lite**의 약자입니다.
*   작고 가벼운 폼팩터의 AI 비전 개발 키트입니다.
*   카메라(RGB, 스테레오), 비전 프로세서(Myriad X)를 내장하고 있습니다.
*   On-device AI 추론(Edge AI)이 가능하여 기기 자체에서 AI 처리를 수행합니다.
*   깊이(Depth) 정보 및 AI 객체 감지, 자세 추정 등 다양한 비전 애플리케이션에 활용됩니다.

---

## 2. 실행 환경 준비

### 2.1. 필수 설치

1.  **Python 3.x 설치 (권장 3.8 이상):**
    *   [Python 공식 웹사이트](https://www.python.org/downloads/)에서 다운로드하여 설치합니다.
    *   **설치 시 "Add Python to PATH" 옵션을 반드시 체크**해야 합니다.
2.  **Git 설치:**
    *   [Git 공식 웹사이트](https://git-scm.com/downloads)에서 다운로드하여 설치합니다.
    *   GitHub 저장소를 클론(복제)하는 데 사용됩니다.
3.  **USB 3.0 포트:**
    *   OAK D-Lite를 컴퓨터의 USB 3.0 (파란색) 포트에 연결합니다. 이는 충분한 전력 공급 및 데이터 전송 속도 확보를 위해 필수적입니다.

### 2.2. 가상 환경 설정 (권장)

*   프로젝트별로 독립적인 파이썬 환경을 구축하여 라이브러리 충돌을 방지합니다.

1.  **프로젝트 폴더 생성 및 이동:**
    ```bash
    mkdir OAK-D-Lite_Project
    cd OAK-D-Lite_Project
    ```
2.  **가상 환경 생성:**
    ```bash
    python -m venv .venv
    ```
3.  **가상 환경 활성화:**
    *   **Windows (PowerShell):**
        ```bash
        .\venv\Scripts\activate
        ```
    *   **macOS/Linux (Bash/Zsh):**
        ```bash
        source .venv/bin/activate
        ```
    *   **확인:** 명령 프롬프트(터미널) 앞에 `(.venv)`가 표시되는지 확인합니다.

---

## 3. DepthAI 저장소 클론 및 데모 실행

*   Luxonis 공식 데모 스크립트를 실행하여 OAK D-Lite 장치 인식 및 필요한 AI 모델 자동 다운로드를 확인합니다.

1.  **`depthai` 저장소 클론 (활성화된 가상 환경에서):**
    ```bash
    git clone https://github.com/luxonis/depthai.git
    ```
    (이 명령은 현재 폴더 안에 `depthai`라는 새로운 폴더를 생성하고 저장소를 복제합니다.)

2.  **클론된 `depthai` 디렉토리로 이동:**
    ```bash
    cd depthai
    ```
    (이제 명령 프롬프트가 `(...)\OAK-D-Lite_Project\depthai>`와 같이 바뀔 것입니다.)

3.  **데모 의존성 설치:**
    *   `depthai_demo.py` 실행에 필요한 모든 파이썬 라이브러리를 설치합니다.
    ```bash
    python install_requirements.py
    ```
    *   **참고:** 이 과정은 `open3d` 등 대용량 라이브러리 설치로 인해 시간이 다소 소요될 수 있습니다.

4.  **`depthai_demo.py` 실행:**
    *   OAK D-Lite를 컴퓨터에 연결한 상태에서 데모 스크립트를 실행합니다.
    ```bash
    python depthai_demo.py
    ```
    *   **목표:** OAK D-Lite가 정상적으로 인식되고, 카메라 영상과 함께 객체 감지 결과가 표시되는 화면이 나타나는지 확인합니다. 이 과정에서 `mobilenet-ssd.blob`과 같은 AI 모델 파일이 자동으로 다운로드됩니다.

---

## 4. 객체 감지 예제 코드 실행

*   이전에 제공된 간단한 객체 감지 파이썬 코드를 실행하여 OAK D-Lite의 기능을 테스트합니다.

1.  **예제 코드 파일 생성:**
    *   `depthai` 폴더 바깥, 또는 `OAK-D-Lite_Project` 루트 폴더(예: `C:\GitHub\JeoninHighSchool\서빙로봇\서빙로봇 소프트웨어\OAK-D-Lite`)에 `object_detection.py` 파일을 생성합니다.
    *   **팁:** VS Code나 메모장으로 파일을 만들 수 있습니다.

2.  **`object_detection.py` 코드 내용:**
    ```python
    import depthai as dai
    import cv2
    import blobconverter # pip install blobconverter로 설치 필요

    # 파이프라인 생성
    pipeline = dai.Pipeline()

    # 카메라 노드 설정 (RGB 카메라)
    cam_rgb = pipeline.create(dai.node.ColorCamera)
    cam_rgb.setPreviewSize(300, 300) # 객체 감지 모델에 맞는 해상도
    cam_rgb.setInterleaved(False)
    cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)
    cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)

    # 객체 감지 모델 로드 (MobileNet SSD)
    nn = pipeline.create(dai.node.MobileNetDetectionNetwork)
    # blobconverter를 사용하여 Luxonis 모델 저장소에서 모델을 자동으로 다운로드하고 경로를 가져옴
    nn.setBlobPath(blobconverter.from_zoo(name="mobilenet-ssd", shaves=6)) 
    nn.setConfidenceThreshold(0.5) # 0.5 이상의 신뢰도만 표시
    nn.input.setBlocking(False)

    # RGB 카메라 출력을 NN 입력에 연결
    cam_rgb.preview.link(nn.input)

    # NN 출력 노드 설정
    xout_nn = pipeline.create(dai.node.XLinkOut)
    xout_nn.setStreamName("nn")
    nn.out.link(xout_nn.input)

    # 카메라 프리뷰 출력 노드 설정
    xout_rgb = pipeline.create(dai.node.XLinkOut)
    xout_rgb.setStreamName("rgb")
    cam_rgb.preview.link(xout_rgb.input)

    # OAK D-Lite 장치에 파이프라인 연결 및 실행
    with dai.Device(pipeline) as device:
        # 출력 큐 설정
        q_rgb = device.getOutputQueue(name="rgb", maxSize=4, blocking=False)
        q_nn = device.getOutputQueue(name="nn", maxSize=4, blocking=False)

        frame = None
        detections = []

        # 'MobileNet SSD' 모델의 클래스 레이블 (예시, 실제 모델에 따라 다를 수 있음)
        # 여기서는 'person'만 감지하도록 가정합니다.
        label_map = ["background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow",
                     "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]

        print("OAK D-Lite에서 객체 감지 시작...")
        print("종료하려면 'q' 키를 누르세요.")

        while True:
            in_rgb = q_rgb.tryGet()
            in_nn = q_nn.tryGet()

            if in_rgb is not None:
                # 카메라 프레임을 OpenCV 이미지로 변환
                frame = in_rgb.getCvFrame()

            if in_nn is not None:
                # NN 결과(감지된 객체들) 가져오기
                detections = in_nn.detections

            if frame is not None:
                height = frame.shape[0]
                width = frame.shape[1]

                # 감지된 객체들에 경계 상자 및 레이블 그리기
                for detection in detections:
                    try:
                        label = label_map[detection.label]
                    except IndexError:
                        label = "Unknown"

                    # 'person'만 필터링하여 표시
                    if label == "person":
                        # 경계 상자 좌표 계산
                        x1 = int(detection.xmin * width)
                        y1 = int(detection.ymin * height)
                        x2 = int(detection.xmax * width)
                        y2 = int(detection.ymax * height)

                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) # 초록색 사각형
                        cv2.putText(frame, f"{label}: {int(detection.confidence * 100)}%",
                                    (x1 + 10, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                cv2.imshow("OAK D-Lite Object Detection (Person)", frame)

            if cv2.waitKey(1) == ord('q'):
                break

    cv2.destroyAllWindows()
    print("객체 감지 종료.")
    ```

3.  **필요 라이브러리 설치:**
    *   아직 설치되지 않았다면, 활성화된 가상 환경에서 다음 명령을 실행합니다.
    ```bash
    (.venv) pip install depthai opencv-python blobconverter
    ```

4.  **코드 실행:**
    *   `object_detection.py` 파일이 있는 디렉토리로 이동한 후 실행합니다.
    *   (예시: `C:\GitHub\JeoninHighSchool\서빙로봇\서빙로봇 소프트웨어\OAK-D-Lite` 디렉토리에서)
    ```bash
    (.venv) python object_detection.py
    ```

---

## 5. 문제 발생 시 대처 방안 (Troubleshooting)

### 5.1. `ModuleNotFoundError: No module named '모듈이름'`

*   **원인:** 특정 파이썬 라이브러리가 현재 가상 환경에 설치되지 않았습니다.
*   **해결:**
    *   에러 메시지에 나온 모듈 이름을 확인하고 `pip install 모듈이름` 명령으로 설치합니다.
    *   일반적으로 `depthai`, `opencv-python`, `blobconverter` 등이 필요합니다.
    *   `depthai` 저장소 내부에서는 `python install_requirements.py`를 실행하여 모든 의존성을 한 번에 설치할 수 있습니다.

### 5.2. `RuntimeError: No available devices`

*   **원인:** 파이썬 스크립트가 OAK D-Lite 장치를 찾을 수 없습니다. (하드웨어 연결 문제, 드라이버 문제, 전원 부족 등이 원인).
*   **해결:**
    *   **하드웨어 연결 확인:** OAK D-Lite가 컴퓨터의 **USB 3.0 포트 (파란색 포트)**에 제대로 연결되어 있는지 확인합니다.
    *   **USB 케이블 확인:** 데이터 전송이 가능한 정품 또는 고품질 USB 3.0 케이블을 사용하고 있는지 확인합니다. 다른 케이블로 교체하여 시도해봅니다.
    *   **Windows 드라이버 설치:**
        *   **Zadig 툴**을 사용하여 OAK D-Lite 장치의 드라이버를 `WinUSB` 또는 `libusbK`로 교체/설치합니다. (Zadig 공식 웹사이트: [https://zadig.akeo.ie/](https://zadig.akeo.ie/))
        *   Zadig 실행 후 `Options` -> `List All Devices` 선택 후 "OAK-D-Lite" 또는 "MyriadX"로 식별되는 장치에 드라이버를 설치해야 합니다.
    *   **다른 프로그램 확인:** 다른 DepthAI 관련 프로그램(예: DepthAI Viewer, 다른 파이썬 스크립트)이 OAK D-Lite를 사용 중인지 확인하고 종료합니다.
    *   **PC 재부팅:** 일시적인 시스템 문제일 수 있으므로 컴퓨터를 재부팅하고 다시 시도해봅니다.

### 5.3. `can't open file '...depthai_demo.py': [Errno 2] No such file or directory`

*   **원인:** `python` 명령을 실행한 현재 디렉토리에서 해당 파일을 찾을 수 없습니다.
*   **해결:**
    *   `cd depthai` 명령을 사용하여 `depthai` 저장소가 클론된 디렉토리로 이동한 후 스크립트를 실행해야 합니다.
    *   `object_detection.py`와 같은 사용자 작성 스크립트의 경우, 해당 파일이 위치한 디렉토리로 이동하여 실행합니다.

---